{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cross validation comparison of different models\n",
    "\n",
    "In this notebook, I compare the accuracy of different models for the pre-processed data of the Kaggle competition Mercedes-Benz Greener Manufacturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_palette('Spectral')\n",
    "import time\n",
    "import os\n",
    "\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickstart\n",
    "# load train and test data\n",
    "train = pd.read_csv('input/train.csv')\n",
    "test = pd.read_csv('input/test.csv')\n",
    "\n",
    "##############################################\n",
    "# homogenize median of duplicates in train set\n",
    "features = train.columns[2:]\n",
    "cat_features = []\n",
    "for c in train.columns:\n",
    "    if train[c].dtype == 'object':\n",
    "        cat_features.append(c)\n",
    "duplicates = train[train.duplicated(subset=features, keep=False)].sort_values(by=cat_features)\n",
    "medians = pd.read_csv('input/X0X118X127medians.csv')\n",
    "medians = medians[medians.columns[:6]]\n",
    "medians = medians.dropna(axis=0, subset=['y_median'])\n",
    "\n",
    "\n",
    "def get_median(a, b, c):\n",
    "    criterion1 = (medians['X0'] == a)\n",
    "    criterion2 = (medians['X118'] == b)\n",
    "    criterion3 = (medians['X127'] == c)\n",
    "    return medians[criterion1 & criterion2 & criterion3].y_median.values[0]\n",
    "\n",
    "\n",
    "def replace_median(df):\n",
    "    df['y'] = get_median(df['X0'], df['X118'], df['X127'])\n",
    "    return df\n",
    "\n",
    "\n",
    "duplicates = duplicates.apply(lambda x: replace_median(x), axis=1)\n",
    "train.loc[train.ID.isin(duplicates.ID), 'y'] = duplicates['y']\n",
    "##############################################################\n",
    "\n",
    "# encode categorical data\n",
    "for c in train.columns:\n",
    "    if train[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[c].values) + list(test[c].values))\n",
    "        train[c] = lbl.transform(list(train[c].values))\n",
    "        test[c] = lbl.transform(list(test[c].values))\n",
    "# remove the previously identified outlier\n",
    "train = train.drop(883, axis=0)\n",
    "X_train = train.drop('y', axis=1)\n",
    "y_train = train['y']\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "        \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        X_transformed = np.copy(X)\n",
    "        \n",
    "        # add class probabilities as a synthetic additional feature\n",
    "        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n",
    "            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n",
    "\n",
    "        # add class prediction as a synthetic additional feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoLarsCV stand-alone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56071456294\nDone: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "lassolarscv = LassoLarsCV()\n",
    "lassolarscv.fit(X_train, y_train)\n",
    "seed = 420\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results_lasso = cross_val_score(lassolarscv, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results_lasso.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.584343771074\nDone: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "# dealt with duplicates\n",
    "t0 = time.time()\n",
    "lassolarscv = LassoLarsCV()\n",
    "lassolarscv.fit(X_train, y_train)\n",
    "seed = 420\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results_lasso = cross_val_score(lassolarscv, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results_lasso.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor stand-alone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0882573111935\nDone: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "seed = 420\n",
    "gradient = GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, \n",
    "                                                          max_features=0.55, min_samples_leaf=18, min_samples_split=14, \n",
    "                                                          subsample=0.7, random_state=seed)\n",
    "gradient.fit(X_train, y_train)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results_gradient = cross_val_score(gradient, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results_gradient.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoLarsCV double-stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.573467511832\nDone: 7.5 s\n"
     ]
    }
   ],
   "source": [
    "stacked_pipeline_1 = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    LassoLarsCV()\n",
    ")\n",
    "\n",
    "# stacked model is trained without the extra features\n",
    "t0 = time.time()\n",
    "stacked_pipeline_1.fit(X_train, y_train)\n",
    "seed = 420\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results_pipe = cross_val_score(stacked_pipeline_1, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results_pipe.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostRegressor / LassoLarsCV stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.595300388475\nDone: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "seed = 420\n",
    "stacked_pipeline_1 = make_pipeline(\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, \n",
    "                                                          max_features=0.55, min_samples_leaf=18, min_samples_split=14, \n",
    "                                                          subsample=0.7, random_state=seed)),\n",
    "    LassoLarsCV()\n",
    ")\n",
    "\n",
    "# stacked model is trained without the extra features\n",
    "t0 = time.time()\n",
    "stacked_pipeline_1.fit(X_train, y_train)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results_pipe = cross_val_score(stacked_pipeline_1, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results_pipe.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoLarsCV / GradientBoostRegressor stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0904126700999\nDone: 45.2 s\n"
     ]
    }
   ],
   "source": [
    "seed = 420\n",
    "stacked_pipeline_1 = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, \n",
    "                                                          max_features=0.55, min_samples_leaf=18, min_samples_split=14, \n",
    "                                                          subsample=0.7, random_state=seed))\n",
    "    \n",
    "# stacked model is trained without the extra features\n",
    "t0 = time.time()\n",
    "stacked_pipeline_1.fit(X_train, y_train)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results_pipe = cross_val_score(stacked_pipeline_1, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results_pipe.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoLarsCV / GradientBoostRegressor / LassoLarsCV stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59736964941\nDone: 43.8 s\n"
     ]
    }
   ],
   "source": [
    "seed = 420\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, \n",
    "                                                          max_features=0.55, min_samples_leaf=18, min_samples_split=14, \n",
    "                                                          subsample=0.7, random_state=seed)),\n",
    "    LassoLarsCV()\n",
    ")\n",
    "# stacked model is trained without the extra features\n",
    "t0 = time.time()\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(stacked_pipeline, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2xLassoLarsCV / GradientBoostRegressor / LassoLarsCV stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.596577261699\nDone: 43.0 s\n"
     ]
    }
   ],
   "source": [
    "seed = 420\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, \n",
    "                                                          max_features=0.55, min_samples_leaf=18, min_samples_split=14, \n",
    "                                                          subsample=0.7, random_state=seed)),\n",
    "    LassoLarsCV()\n",
    ")\n",
    "# stacked model is trained without the extra features\n",
    "t0 = time.time()\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(stacked_pipeline, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoLarsCV / GradientBoostRegressor / 2xLassoLarsCV stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.597468073476\nDone: 42.9 s\n"
     ]
    }
   ],
   "source": [
    "seed = 420\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, \n",
    "                                                          max_features=0.55, min_samples_leaf=18, min_samples_split=14, \n",
    "                                                          subsample=0.7, random_state=seed)),\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    LassoLarsCV()\n",
    ")\n",
    "# stacked model is trained without the extra features\n",
    "t0 = time.time()\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(stacked_pipeline, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.624437143926\nDone: 45.8 s\n"
     ]
    }
   ],
   "source": [
    "# dealt with duplicates\n",
    "seed = 420\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, \n",
    "                                                          max_features=0.55, min_samples_leaf=18, min_samples_split=14, \n",
    "                                                          subsample=0.7, random_state=seed)),\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    LassoLarsCV()\n",
    ")\n",
    "# stacked model is trained without the extra features\n",
    "t0 = time.time()\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(stacked_pipeline, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tested models and stacking configurations, this one provided the second highest accuracy. The best accuracy was provided by the next configuration, however with only a marginal increase. To reduce the risk of overfitting, we select this model as the best stacking model from the group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoLarsCV / GradientBoostRegressor / 3xLassoLarsCV stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.597471532978\nDone: 46.4 s\n"
     ]
    }
   ],
   "source": [
    "seed = 420\n",
    "stacked_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, \n",
    "                                                          max_features=0.55, min_samples_leaf=18, min_samples_split=14, \n",
    "                                                          subsample=0.7, random_state=seed)),\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
    "    LassoLarsCV()\n",
    ")\n",
    "# stacked model is trained without the extra features\n",
    "t0 = time.time()\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(stacked_pipeline, X_train, y_train, cv=kfold)\n",
    "print('Accuracy:', results.mean())\n",
    "print(\"Done: {:.1f} s\".format(time.time() - t0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}